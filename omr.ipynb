{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: \"Shivani Khandelwal\"\n",
    "\n",
    "Reference: Murtaza Hassan - https://youtu.be/0IqCOPlGBTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stackImages(img_array, scale):\n",
    "    rows = len(img_array)\n",
    "    cols = len(img_array[0])\n",
    "\n",
    "    rowsAvailable = isinstance(img_array[0], list)\n",
    "    height = img_array[0][0].shape[0]\n",
    "    width = img_array[0][0].shape[1]\n",
    "\n",
    "    if rowsAvailable:\n",
    "        for r in range(0, rows):\n",
    "            for c in range(0, cols):\n",
    "                img_array[r][c] = cv2.resize(img_array[r][c], (0, 0), None, scale, scale)\n",
    "                if len(img_array[r][c].shape) == 2:\n",
    "                    img_array[r][c] = cv2.cvtColor(img_array[r][c], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(img_array[x])\n",
    "        ver = np.vstack(hor)\n",
    "        \n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            img_array[x] = cv2.resize(img_array[x], (0, 0), None, scale, scale)\n",
    "            if len(img_array[x].shape) == 2:\n",
    "                img_array[x] = cv2.cvtColor(img_array[x], cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        hor = np.hstack(img_array)\n",
    "        ver = hor\n",
    "\n",
    "    return ver\n",
    "\n",
    "\n",
    "def rectContour(contours):\n",
    "    rectCon = []\n",
    "    for con in contours:\n",
    "        area = cv2.contourArea(con)\n",
    "        if area > 50:\n",
    "            peri = cv2.arcLength(con, True)\n",
    "            approx = cv2.approxPolyDP(con, 0.02*peri, True)\n",
    "            if len(approx) == 4:\n",
    "                rectCon.append(approx)\n",
    "                \n",
    "    rectCon = sorted(rectCon, key=cv2.contourArea, reverse=True)\n",
    "    return rectCon\n",
    "\n",
    "\n",
    "def reorderPoints(points):\n",
    "    points = points.reshape((4, 2))\n",
    "    ordered_points = np.zeros((4, 1, 2), np.int32)\n",
    "\n",
    "    add = np.sum(points, axis=1)\n",
    "    ordered_points[0] = points[np.argmin(add)]\n",
    "    ordered_points[3] = points[np.argmax(add)]\n",
    "    \n",
    "    diff = np.diff(points, axis=1)\n",
    "    ordered_points[1] = points[np.argmin(diff)]\n",
    "    ordered_points[2] = points[np.argmax(diff)]\n",
    "\n",
    "    return ordered_points\n",
    "\n",
    "\n",
    "def splitBoxes(img):\n",
    "    rows = np.vsplit(img, 5)\n",
    "    boxes = []\n",
    "    for r in rows:\n",
    "        cols = np.hsplit(r, 5)\n",
    "        boxes.extend(cols)\n",
    "        \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "omr1 = cv2.imread('images/omr_1.jpg')\n",
    "print(omr1.shape)\n",
    "\n",
    "height = 700\n",
    "width = 700\n",
    "\n",
    "questions = 5\n",
    "choices = 5\n",
    "answers = [1, 2, 0, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 700)\n"
     ]
    }
   ],
   "source": [
    "omr1 = cv2.resize(omr1, (width, height))\n",
    "\n",
    "omr1_gray = cv2.cvtColor(omr1, cv2.COLOR_BGR2GRAY)\n",
    "omr1_blur = cv2.GaussianBlur(omr1_gray, (5, 5), 1) # Sigma (Std.) defines the amount of blurring - 1\n",
    "omr1_canny = cv2.Canny(omr1_blur, 10, 50)\n",
    "print(omr1_canny.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, hierarchy = cv2.findContours(omr1_canny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "omr1_contours = cv2.drawContours(omr1.copy(), contours, -1, (0, 255, 0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_con = rectContour(contours)\n",
    "\n",
    "marking_area = rect_con[0]\n",
    "grading_area = rect_con[1]\n",
    "\n",
    "if marking_area.size != 0 and grading_area.size != 0:\n",
    "    omr1_selected_area = cv2.drawContours(omr1.copy(), marking_area, -1, (255, 0, 0), 10)\n",
    "    omr1_selected_area = cv2.drawContours(omr1_selected_area, grading_area, -1, (0, 0, 255), 10)\n",
    "\n",
    "    marking_area = reorderPoints(marking_area)\n",
    "    grading_area = reorderPoints(grading_area)\n",
    "\n",
    "    marking_pt1 = np.float32(marking_area)\n",
    "    marking_pt2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "    matrix = cv2.getPerspectiveTransform(marking_pt1, marking_pt2)\n",
    "    marking_res = cv2.warpPerspective(omr1.copy(), matrix, (width, height))\n",
    "\n",
    "    grading_pt1 = np.float32(grading_area)\n",
    "    grading_pt2 = np.float32([[0, 0], [width, 0], [0, height], [width, height]])\n",
    "    matrix = cv2.getPerspectiveTransform(grading_pt1, grading_pt2)\n",
    "    grading_res = cv2.warpPerspective(omr1.copy(), matrix, (width, height))\n",
    "\n",
    "    marking_res_gray = cv2.cvtColor(marking_res, cv2.COLOR_BGR2GRAY)\n",
    "    marking_res_thres = cv2.threshold(marking_res_gray, 170, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "\n",
    "    boxes = splitBoxes(marking_res_thres)\n",
    "    pixel_val = np.zeros((questions, choices))\n",
    "\n",
    "    for b in range(len(boxes)):\n",
    "        total_pixels = cv2.countNonZero(boxes[b])\n",
    "        if total_pixels > 5000:\n",
    "            row = int(b/questions)\n",
    "            col = b % choices\n",
    "            pixel_val[row][col] = 1\n",
    "\n",
    "    grading = []\n",
    "    for i in range(questions):\n",
    "        index = np.where(pixel_val[i] == 1)[0]\n",
    "        if len(index) == 0:\n",
    "            grading.append(-1)\n",
    "        else:\n",
    "            grading.append(index[0])\n",
    "\n",
    "    score = 0\n",
    "    for i in range(questions):\n",
    "        if grading[i] == answers[i]:\n",
    "            score += 1\n",
    "\n",
    "    final_score = (score/questions)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 0, 4]\n",
      "4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blank = np.zeros_like(omr1)\n",
    "img_array = [[omr1, omr1_gray, omr1_blur, omr1_canny],\n",
    "             [omr1_contours, omr1_selected_area, marking_res, marking_res_thres]]\n",
    "img_stack = stackImages(img_array, 0.5)\n",
    "\n",
    "cv2.imshow('Stacked Images', img_stack)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
